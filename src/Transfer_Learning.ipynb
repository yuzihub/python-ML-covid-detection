{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c92448d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x1c824563130>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing required modules\n",
    "from __future__ import print_function, division\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms as T\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cefc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring batch size\n",
    "batch_size = 32\n",
    "\n",
    "#applying required transformations on the dataset\n",
    "img_transforms = {\n",
    "    'train':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(224,224)), \n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "        ]),\n",
    "\n",
    "    'valid':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ]),\n",
    "\n",
    "    'test':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ]),\n",
    "     }\n",
    "\n",
    "#creating Location of data: train, validation, test\n",
    "data='./data/'\n",
    "\n",
    "train_path=os.path.join(data,'train')\n",
    "valid_path=os.path.join(data,'test')\n",
    "test_path=os.path.join(data,'valid')\n",
    "\n",
    "\n",
    "#creating Datasets to each of  folder created in prev\n",
    "train_file=datasets.ImageFolder(train_path,transform=img_transforms['train'])\n",
    "valid_file=datasets.ImageFolder(valid_path,transform=img_transforms['valid'])\n",
    "test_file=datasets.ImageFolder(test_path,transform=img_transforms['test'])\n",
    "\n",
    "\n",
    "#creating loaders for the dataset\n",
    "loaders_transfer={\n",
    "    'train':torch.utils.data.DataLoader(train_file,batch_size,shuffle=True),\n",
    "    'val':torch.utils.data.DataLoader(valid_file,batch_size,shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(test_file,batch_size,shuffle=True)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_file),\n",
    "    'val': len(valid_file),\n",
    "    'test': len(test_file)\n",
    "}\n",
    "\n",
    "class_names = train_file.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6de21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abcf807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:  \n",
    "    dev = \"cuda\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev) \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8098b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the pretrained resnet18 model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2e2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in loaders_transfer[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd736379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2939 Acc: 0.8761\n",
      "val Loss: 0.1467 Acc: 0.9452\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0746 Acc: 0.9775\n",
      "val Loss: 0.0350 Acc: 0.9956\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0373 Acc: 0.9902\n",
      "val Loss: 0.0279 Acc: 0.9956\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 0.9935\n",
      "val Loss: 0.0116 Acc: 1.0000\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0153 Acc: 0.9981\n",
      "val Loss: 0.0247 Acc: 0.9934\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0126 Acc: 0.9977\n",
      "val Loss: 0.0184 Acc: 0.9934\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0082 Acc: 0.9995\n",
      "val Loss: 0.0168 Acc: 0.9956\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 1.0000\n",
      "val Loss: 0.0173 Acc: 0.9934\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0065 Acc: 0.9991\n",
      "val Loss: 0.0143 Acc: 0.9956\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0058 Acc: 0.9995\n",
      "val Loss: 0.0148 Acc: 0.9956\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0073 Acc: 0.9991\n",
      "val Loss: 0.0139 Acc: 0.9956\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0057 Acc: 0.9991\n",
      "val Loss: 0.0132 Acc: 0.9956\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 1.0000\n",
      "val Loss: 0.0072 Acc: 1.0000\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0040 Acc: 1.0000\n",
      "val Loss: 0.0096 Acc: 0.9978\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0059 Acc: 1.0000\n",
      "val Loss: 0.0100 Acc: 0.9978\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0062 Acc: 0.9995\n",
      "val Loss: 0.0167 Acc: 0.9956\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0075 Acc: 0.9991\n",
      "val Loss: 0.0085 Acc: 1.0000\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0087 Acc: 0.9986\n",
      "val Loss: 0.0098 Acc: 1.0000\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "val Loss: 0.0096 Acc: 0.9978\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "val Loss: 0.0081 Acc: 1.0000\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0065 Acc: 0.9995\n",
      "val Loss: 0.0119 Acc: 0.9956\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "val Loss: 0.0108 Acc: 0.9978\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "val Loss: 0.0103 Acc: 0.9978\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0056 Acc: 0.9995\n",
      "val Loss: 0.0115 Acc: 0.9978\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 1.0000\n",
      "val Loss: 0.0156 Acc: 0.9956\n",
      "\n",
      "Training complete in 27m 48s\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2474f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the test function\n",
    "\n",
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitoring test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # moving to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # updating average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # converting the output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        preds.append(pred)\n",
    "        targets.append(target)\n",
    "        # compare predictions\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "    \n",
    "    return preds, targets\n",
    "\n",
    "# calling test function\n",
    "preds, targets = test(loaders_transfer, model_ft, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48c7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the tensor object to a list for metric functions\n",
    "\n",
    "preds2, targets2 = [],[]\n",
    "\n",
    "for i in preds:\n",
    "      for j in range(len(i)):\n",
    "        preds2.append(i.cpu().numpy()[j])\n",
    "for i in targets:\n",
    "      for j in range(len(i)):\n",
    "        targets2.append(i.cpu().numpy()[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7554378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "#Computing the accuracy\n",
    "acc = accuracy_score(targets2, preds2)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9588d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       228\n",
      "           1       0.99      0.99      0.99       228\n",
      "\n",
      "    accuracy                           0.99       456\n",
      "   macro avg       0.99      0.99      0.99       456\n",
      "weighted avg       0.99      0.99      0.99       456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_report = classification_report(preds2, targets2)\n",
    "print(perf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89397f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
